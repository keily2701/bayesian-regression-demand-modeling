---
title: "Análisis estadístico de brotes alimentarios"
author: "Keily Oropeza"
output: html_document
---

## Introducción

Este documento presenta una versión resumida y reproducible del análisis
estadístico desarrollado en mi tesis de grado en Matemática (mención Estadística
y Aplicadas).  
El estudio se centra en el análisis de brotes de enfermedades transmitidas por
alimentos, utilizando datos previamente modificados con fines académicos.

---

## Carga y preparación de los datos

```{r}
# Limpiar entorno
rm(list = ls())

# Librerías
library(glmnet)

# Cargar datos
source("src/load_data.R")
source("eda_multivariate.R")
source("eda_univariate.R")
source("glm_models.R")
source("pca_analysis.R")
source("regularized_models.R")


data_list <- cargar_datos("data/data modificada 5 sem1.csv")

dato1 <- data_list$dato1
vari  <- data_list$variables
```
El conjunto de datos contiene información epidemiológica de brotes de ETA,
incluyendo variables categóricas, binarias y de conteo, las cuales son analizadas
según su naturaleza.
---

## Análisis exploratorio

### Resumen descriptivo global

Se realizó un análisis descriptivo de las variables cuantitativas mediante medidas resumen, rango, desviación estándar y varianza, con el fin de evaluar dispersión, escalas y posibles valores atípicos.

```{r}
summary(dato1)

apply(dato1, 2, range)
apply(dato1, 2, sd)
apply(dato1, 2, var)
```
### Variables binarias
A continuación se presentan algunas visualizaciones descriptivas de variables
seleccionadas, con el fin de identificar patrones iniciales.

```{r}
# Variables binarias
indices_sintomas <- c(29:44)
indices_otras    <- c(6, 55, 56)
indices_binarias <- c( indices_sintomas,indices_otras)

par(mfrow = c(3, 3))
for (i in indices_sintomas) {
  plot_binary_hist(dato1, i)
}

par(mfrow = c(1, 3))

for (i in indices_otras) {
  plot_binary_hist(dato1, i)
}

# Tabla resumen
binary_summary(dato1, indices_binarias)

```
### Variables categóricas
Para las variables categóricas se construyeron histogramas y tablas de frecuencia absoluta y relativa mediante una función auxiliar, lo que permite manejar variables con distinto número de niveles de forma automática.

```{r}
indices_factores <- c(
  1, 4, 5,
  45,46,47,48,49,50,51,52,
  53,54
)
par(mfrow = c(1, 3))# variables-Temporal y geografico

for (i in indices_factores[1:3]) {
  plot_factor_hist(
    dato1,
    i,
    breaks = seq(min(dato1[,i]) - 0.5,
                 max(dato1[,i]) + 0.5,
                 by = 1)
  )
}

par(mfrow = c(2, 4)) # variables- Otros factores

for (i in indices_factores[4:11]) {
  plot_factor_hist(
    dato1,
    i,
    breaks = seq(min(dato1[,i]) - 0.5,
                 max(dato1[,i]) + 0.5,
                 by = 1)
  )
}

par(mfrow = c(1, 2))# variables- Diagnostico 

for (i in indices_factores[12:13]) {
  plot_factor_hist(
    dato1,
    i,
    breaks = seq(min(dato1[,i]) - 0.5,
                 max(dato1[,i]) + 0.5,
                 by = 1)
  )
}

tablas_factores <- lapply(indices_factores, function(i){
  factor_summary(dato1, i)
})

names(tablas_factores) <- vari[indices_factores]
```
---
### Variables de conteo

Para las variables Expuestos y Enfermos se utilizaron diagramas de caja, permitiendo identificar asimetrías, valores extremos y diferencias en magnitud entre brotes.

```{r}
# Variable de interés principal
par(mfrow = c(1, 2))
boxplot(dato1[, 8], main = "Distribución del número de enfermos",
        ylab = "Enfermos")
boxplot(dato1[, 7], main = "Distribución del número de expuestos",
        ylab = "Expuestos")
```
---
## Modelo lineal generalizado para la variable *Enfermos*
Se construyó la matriz de diseño mediante model.matrix, incorporando variables categóricas mediante codificación dummy.
La variable respuesta corresponde al número de personas enfermas por brote.

```{r}
# modificacion de extructura de datos para hacer modelo lineal
dato10=data.frame(dato1)
head(dato10)
```


Dado que la variable respuesta *Enfermos* corresponde a un conteo, se ajustaron
modelos lineales generalizados (GLM) bajo la distribución Poisson, con el fin de
establecer un modelo base de referencia previo al uso de técnicas penalizadas.
```{r}
m1 <- glm(
  Enfermos ~ .,
  data = dato10,
  family = poisson
)

summary(m1)
```
Este primer modelo incorpora la totalidad de las covariables disponibles,
permitiendo evaluar su efecto conjunto sobre el número de personas enfermas.

Debido a problemas de colinealidad, redundancia y variables derivadas, se ajustó
un segundo modelo excluyendo variables altamente correlacionadas o no informativas.

```{r}
m2 <- glm(
  Enfermos ~ . -
    Año.estadistico -
    Fallecidos -
    Tasa.Letalidad -
    total.de.fallecidos -
    Hipoestesias -
    Paralisis -
    Otros.Neurológicos,
  data = dato10,
  family = poisson
)

resu1 <- summary(m2)
resu1
coe_m2 <- resu1$coefficients
head(coe_m2)
```
La exclusión de variables responde a su relación directa con la variable respuesta
o a su baja frecuencia, lo que podría afectar la estabilidad del modelo.
```{r}
m3 <- glm(
  Enfermos ~ . -
    Año.estadistico -
    Fallecidos -
    Tasa.Letalidad -
    total.de.fallecidos -
    Hipoestesias -
    Paralisis -
    Otros.Neurológicos -
    Total.ambulatorios -
    total.de.Hospitalizados -
    total.sin.atención,
  data = dato10,
  family = poisson
)

resu2 <- summary(m3)
resu2

coe_m3 <- resu2$coefficients
head(coe_m3)
```
Este modelo busca un equilibrio entre capacidad explicativa y parsimonia,
reduciendo el número de covariables sin perder interpretabilidad.

### Análisis de Componentes Principales

Con el fin de explorar la estructura multivariada de los datos y evaluar la
posible correlación entre las covariables, se realizó un Análisis de Componentes
Principales (PCA). Este análisis permite reducir la dimensionalidad y detectar
patrones de variabilidad relevantes antes de la aplicación de modelos penalizados.
Se excluyó la variable Enfermos del PCA por corresponder a la variable respuesta del estudio.
```{r}
pca_eta <- princomp(
  dato1[, -8],
  cor = TRUE
)
```
El análisis se realizó sobre las variables cuantitativas, utilizando la matriz de
correlaciones con el fin de evitar el efecto de las distintas escalas de medición.

```{r}
plot(pca_eta, col = "tomato3")
screeplot(pca_eta, type = "lines")
```
El gráfico de sedimentación permite evaluar la proporción de varianza explicada
por cada componente principal y sugiere la presencia de una estructura de
dimensionalidad reducida.
```{r}
loadings(pca_eta)
```
Las cargas factoriales indican la contribución de cada variable original a las
componentes principales, permitiendo identificar grupos de variables con
comportamiento similar.
```{r}
biplot(pca_eta)
```
El biplot permite visualizar simultáneamente observaciones y variables, destacando
relaciones de correlación y direcciones de máxima variabilidad.
```{r}
par(mfrow = c(2,2), bg = "azure")

for (i in 1:4) {
  barplot(
    loadings(pca_eta)[, i],
    col = "blue2",
    main = paste("Componente", i)
  )
}
```
Los gráficos de barras de las primeras componentes permiten identificar las
variables con mayor contribución a la variabilidad total del sistema.
```{r}
head(pca_eta$scores)
```
Los scores representan las observaciones proyectadas en el nuevo espacio de
componentes principales.

La presencia de correlación entre covariables y la alta dimensionalidad observada
refuerzan la necesidad de utilizar métodos de regularización, como la regresión
LASSO, que permiten estabilizar las estimaciones y realizar selección automática
de variables.

---
## Modelos de regresión penalizada: LASSO

```{r}
# modelo LASSO
x = model.matrix(Enfermo ~ ., dato10)
y = dato10$Enfermo
```

```{r}
set.seed(1)

n <- nrow(x)
train <- sample(seq_len(n), size = floor(n / 2))
test  <- setdiff(seq_len(n), train)

y.test <- y[test]
grid =10^ seq (10,-2, length =100)
```

Se ajustó un modelo LASSO clásico utilizando la librería glmnet, explorando una grilla logarítmica de valores del parámetro de penalización λ.

```{r}
lasso.mod = glmnet(x[train,], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
```


```{r}
cv.out <- cv.glmnet(
  x[train, ],
  y[train],
  alpha = 1
)

plot(cv.out)

bestlam <- cv.out$lambda.min
bestlam
```


```{r}
lasso.pred <- predict(
  lasso.mod,
  s = bestlam,
  newx = x[test, ]
)

mse_lasso <- mean((lasso.pred - y.test)^2)
mse_lasso

r2_lasso <- 1 - mean((y.test - lasso.pred)^2) /
                  mean((y.test - mean(y.test))^2)
r2_lasso
ecm=c( mean(( lasso.pred -y.test)^2))
```

Los coeficientes distintos de cero representan las variables seleccionadas por
el procedimiento LASSO, las cuales son consideradas relevantes en el análisis.

```{r}
coef_lasso <- as.matrix(coef(lasso.mod, s = bestlam))
coef_no_nulos <- coef_lasso[coef_lasso[,1] != 0, , drop = FALSE]
coef_no_nulos[-1, , drop = FALSE]
```

```{r}
dato_df <- data.frame(dato1)

modelo_poisson <- glm(
  Enfermos ~ . - Año.estadistico - Fallecidos - Tasa.Letalidad,
  data = dato_df,
  family = poisson
)

summary(modelo_poisson)

```

---

## Regresión Ridge

Además del modelo LASSO, se ajustó un modelo de regresión Ridge con el fin de
comparar el efecto de distintas estrategias de regularización. A diferencia del
LASSO, Ridge no realiza selección de variables, pero es especialmente útil en
presencia de multicolinealidad.
```{r}
ridge.mod <- glmnet(
  x,
  y,
  alpha = 0,
  lambda = grid
)

plot(ridge.mod)
```
El modelo Ridge se ajustó utilizando una grilla de valores del parámetro de
penalización λ, permitiendo evaluar la contracción progresiva de los coeficientes.

```{r}
coef_ridge <- as.matrix(coef(ridge.mod))
```
A diferencia del LASSO, los coeficientes del modelo Ridge no se anulan exactamente,
sino que son suavemente contraídos hacia cero.
```{r}
lambda_max <- max(ridge.mod$lambda)
coef_max  <- coef(ridge.mod)[ridge.mod$lambda == lambda_max]

sqrt(sum(coef_max[-1]^2))
```

```{r}

sqrt(sum(coef(ridge.mod)[-1, 20]^2))
```
La norma euclidiana del vector de coeficientes disminuye a medida que aumenta λ,
reflejando el efecto de la penalización Ridge.
```{r}
ridge.mod <- glmnet(
  x[train, ],
  y[train],
  alpha = 0,
  lambda = grid,
  thresh = 1e-12
)
```

```{r}
ridge.pred <- predict(
  ridge.mod,
  s = 4,
  newx = x[test, ]
)

mean((ridge.pred - y.test)^2)
mean((mean(y[train]) - y.test)^2)
```
El desempeño predictivo del modelo Ridge se comparó con un modelo base, utilizando
el error cuadrático medio como métrica de evaluación.
```{r}
cv.out <- cv.glmnet(
  x[train, ],
  y[train],
  alpha = 0
)

plot(cv.out)

bestlam_ridge <- cv.out$lambda.min
bestlam_ridge
```
```{r}
ridge.pred <- predict(
  ridge.mod,
  s = bestlam_ridge,
  newx = x[test, ]
)

mean((ridge.pred - y.test)^2)
```
```{r}
out <- glmnet(x, y, alpha = 0)
ridge.coef <- predict(out, type = "coefficients", s = bestlam_ridge)

ridge.coef[ridge.coef != 0]
```
El modelo Ridge mantiene todas las covariables en el modelo final, aunque con
coeficientes reducidos, lo que contrasta con el comportamiento selectivo del LASSO.
```{r}
plot(
  ridge.pred,
  y.test,
  main = "Predicciones Ridge vs valores reales",
  xlab = "Predicción",
  ylab = "Observado"
)
```
```{r}
ecm <- c(ecm, mean((ridge.pred - y.test)^2))
names(ecm) <- c("LASSO", "RIDGE")
ecm
```
La comparación de los errores cuadráticos medios permite evaluar el compromiso
entre capacidad predictiva y parsimonia de los distintos modelos ajustados.

---


## 9. Conclusiones

El análisis exploratorio permitió identificar patrones relevantes en la
distribución de síntomas y variables asociadas a los brotes alimentarios.

El modelo Poisson y la regularización LASSO evidencian que un subconjunto reducido
de variables explica gran parte de la variabilidad observada en el número de
enfermos, destacando la utilidad de técnicas de selección de variables en
problemas reales de salud pública.

La comparación entre modelos clásicos y regularizados evidencia que la
regularización resulta especialmente útil en contextos con alta dimensionalidad
y colinealidad, permitiendo mejorar la estabilidad de las estimaciones sin perder
capacidad predictiva.
